{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ_oHGiyFpn_",
        "outputId": "a85e90fe-a92e-490e-cdf6-fa7154f2980a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.31)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.10/dist-packages (0.1.129)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.2.39 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.3.7)\n",
            "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.14 in /usr/local/lib/python3.10/dist-packages (from langgraph) (1.0.14)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith) (3.10.7)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<2.0.0,>=1.0.14->langgraph) (1.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (2.2.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.39->langgraph) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph langsmith"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_groq langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5cn_pztF6RQ",
        "outputId": "a5079a70-80db-4748-ea39-f9f370445c95"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.7)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.129)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.2.0-py3-none-any.whl (14 kB)\n",
            "Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, groq, dataclasses-json, langchain-text-splitters, langchain_groq, langchain, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 groq-0.11.0 langchain-0.3.1 langchain-text-splitters-0.3.0 langchain_community-0.3.1 langchain_groq-0.2.0 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('groq_api_key')\n",
        "langsmith = userdata.get('LANGSMITH_API_KEY')"
      ],
      "metadata": {
        "id": "8ZUp_0xeGUTa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = langsmith\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Tut_langgraph\""
      ],
      "metadata": {
        "id": "VYVKo9h4HyzD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "qnXKXIjvJVRH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama3-70b-8192\")\n",
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7LX4Y4aJh1Q",
        "outputId": "f5a1dceb-24e9-44f0-d4ee-08f18e3596ee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7dd6c03d0880>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7dd6c03d1540>, model_name='llama3-70b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CHATBOT using LangGraph\n"
      ],
      "metadata": {
        "id": "IN-mvLxGKNm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph,START,END\n",
        "from langgraph.graph.message import add_messages"
      ],
      "metadata": {
        "id": "7UYL_-OhKBib"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "  messages:Annotated[list,add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "lQgPfApxK13G"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAYd5XTJLaRa",
        "outputId": "888ed791-c6f4-4302-967b-cb36ae1b8b03"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7dd6c03d1ea0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state:State):\n",
        "  return {\"messages\":llm.invoke(state[\"messages\"])}"
      ],
      "metadata": {
        "id": "HmRUxna9Levz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_node(\"chatbot\",chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UaWIFHZhFBo",
        "outputId": "67c42927-62d2-42e4-cebf-9830b66975dc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7dd6c03d1ea0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START,\"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\",END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy3XU_NAhQjF",
        "outputId": "e2f9b2dc-4b91-4a13-e804-a3965efd9020"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7dd6c03d1ea0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph=graph_builder.compile()"
      ],
      "metadata": {
        "id": "layOm_xZhnkF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying Graph\n",
        "\n",
        "from IPython.display import Image,display\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "Dv0yM9X-hq4F",
        "outputId": "59df3409-0df1-4bba-8334-177aeda4b424"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input = input(\"User: \")\n",
        "  if user_input.lower() in [\"quit\",\"q\"]:\n",
        "    print(\"Good Bye\")\n",
        "    break\n",
        "  for event in graph.stream({'messages':(\"user\",user_input)}):\n",
        "    print(event.values())\n",
        "    for value in event.values():\n",
        "      print(value['messages'])\n",
        "      print(\"Assistant:\",value['messages'].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt9eJNDLiFBB",
        "outputId": "04d5a3d2-723f-4039-ef40-73aa98265802"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: who is Andrew kalpathy\n",
            "dict_values([{'messages': AIMessage(content='Andrew Kalpathy! From what I gathered, Andrew Kalpathy is a popular Canadian film editor, director, and screenwriter. He is best known for his work on various documentaries, short films, and feature films.\\n\\nOne of his notable works is the 2019 documentary film \" Tigers\" (also known as \"Playing with Fire\" in some regions), which explores the dark side of the infant formula industry and its impact on Chinese consumers. Kalpathy co-directed and edited the film, which received critical acclaim and won several awards.\\n\\nKalpathy has also worked on other documentaries, such as \"The Anthem\" (2017) and \"The Messenger\" (2015), which focus on social and environmental issues. His work often highlights important global concerns and sheds light on lesser-known stories.\\n\\nIf you\\'re interested in learning more about Andrew Kalpathy\\'s work or watching his films, I recommend checking out online platforms like IMDb, Vimeo, or YouTube, where you can find more information and trailers for his projects.\\n\\nWould you like to know more about a specific aspect of Andrew Kalpathy\\'s work or career?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 227, 'prompt_tokens': 16, 'total_tokens': 243, 'completion_time': 0.734649428, 'prompt_time': 0.000298157, 'queue_time': 0.013972432, 'total_time': 0.734947585}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None}, id='run-5a191fde-4ef1-47a7-ac1c-952b0a18eeb3-0', usage_metadata={'input_tokens': 16, 'output_tokens': 227, 'total_tokens': 243})}])\n",
            "content='Andrew Kalpathy! From what I gathered, Andrew Kalpathy is a popular Canadian film editor, director, and screenwriter. He is best known for his work on various documentaries, short films, and feature films.\\n\\nOne of his notable works is the 2019 documentary film \" Tigers\" (also known as \"Playing with Fire\" in some regions), which explores the dark side of the infant formula industry and its impact on Chinese consumers. Kalpathy co-directed and edited the film, which received critical acclaim and won several awards.\\n\\nKalpathy has also worked on other documentaries, such as \"The Anthem\" (2017) and \"The Messenger\" (2015), which focus on social and environmental issues. His work often highlights important global concerns and sheds light on lesser-known stories.\\n\\nIf you\\'re interested in learning more about Andrew Kalpathy\\'s work or watching his films, I recommend checking out online platforms like IMDb, Vimeo, or YouTube, where you can find more information and trailers for his projects.\\n\\nWould you like to know more about a specific aspect of Andrew Kalpathy\\'s work or career?' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 227, 'prompt_tokens': 16, 'total_tokens': 243, 'completion_time': 0.734649428, 'prompt_time': 0.000298157, 'queue_time': 0.013972432, 'total_time': 0.734947585}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None} id='run-5a191fde-4ef1-47a7-ac1c-952b0a18eeb3-0' usage_metadata={'input_tokens': 16, 'output_tokens': 227, 'total_tokens': 243}\n",
            "Assistant: Andrew Kalpathy! From what I gathered, Andrew Kalpathy is a popular Canadian film editor, director, and screenwriter. He is best known for his work on various documentaries, short films, and feature films.\n",
            "\n",
            "One of his notable works is the 2019 documentary film \" Tigers\" (also known as \"Playing with Fire\" in some regions), which explores the dark side of the infant formula industry and its impact on Chinese consumers. Kalpathy co-directed and edited the film, which received critical acclaim and won several awards.\n",
            "\n",
            "Kalpathy has also worked on other documentaries, such as \"The Anthem\" (2017) and \"The Messenger\" (2015), which focus on social and environmental issues. His work often highlights important global concerns and sheds light on lesser-known stories.\n",
            "\n",
            "If you're interested in learning more about Andrew Kalpathy's work or watching his films, I recommend checking out online platforms like IMDb, Vimeo, or YouTube, where you can find more information and trailers for his projects.\n",
            "\n",
            "Would you like to know more about a specific aspect of Andrew Kalpathy's work or career?\n",
            "User: what are u trained on?\n",
            "dict_values([{'messages': AIMessage(content=\"I am trained on a massive dataset of text from various sources, including but not limited to:\\n\\n1. **Web pages**: I was trained on a large corpus of web pages to learn about various topics, styles, and formats.\\n2. **Books and articles**: I have been trained on a vast collection of books and articles from different genres, domains, and languages.\\n3. **User-generated content**: I've been trained on a large amount of user-generated content from social media, forums, and other online platforms.\\n4. **Product reviews**: I've seen millions of product reviews to learn about different products, services, and opinions.\\n5. **Conversations**: I've been trained on a vast amount of conversational data to learn how to respond to questions, statements, and prompts.\\n6. **Knowledge graphs**: I have access to large knowledge graphs that contain structured data about entities, relationships, and concepts.\\n7. **Databases**: I've been trained on various databases that contain information about different topics, including but not limited to history, science, technology, and more.\\n\\nMy training data is sourced from various places, including but not limited to:\\n\\n1. **Common Crawl**: A non-profit organization that crawls the web and makes the data available for research and development.\\n2. **Wikipedia**: A free online encyclopedia that provides a vast amount of knowledge on various topics.\\n3. **Books and academic papers**: I've been trained on a large collection of books and academic papers to learn about different subjects and domains.\\n4. **Online forums and discussions**: I've been trained on various online forums and discussions to learn about different topics, opinions, and perspectives.\\n5. **Product reviews and ratings**: I've been trained on a large amount of product reviews and ratings to learn about different products and services.\\n\\nMy training data is constantly updated and expanded to keep my knowledge up-to-date and to improve my performance.\\n\\nI'm a large language model, I don't have personal experiences, emotions, or opinions. My responses are generated based on patterns and relationships in the data I've been trained on.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 426, 'prompt_tokens': 16, 'total_tokens': 442, 'completion_time': 1.344802009, 'prompt_time': 0.000286179, 'queue_time': 0.012790188000000001, 'total_time': 1.345088188}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None}, id='run-b48f3626-44a8-4933-a8bd-8de018749410-0', usage_metadata={'input_tokens': 16, 'output_tokens': 426, 'total_tokens': 442})}])\n",
            "content=\"I am trained on a massive dataset of text from various sources, including but not limited to:\\n\\n1. **Web pages**: I was trained on a large corpus of web pages to learn about various topics, styles, and formats.\\n2. **Books and articles**: I have been trained on a vast collection of books and articles from different genres, domains, and languages.\\n3. **User-generated content**: I've been trained on a large amount of user-generated content from social media, forums, and other online platforms.\\n4. **Product reviews**: I've seen millions of product reviews to learn about different products, services, and opinions.\\n5. **Conversations**: I've been trained on a vast amount of conversational data to learn how to respond to questions, statements, and prompts.\\n6. **Knowledge graphs**: I have access to large knowledge graphs that contain structured data about entities, relationships, and concepts.\\n7. **Databases**: I've been trained on various databases that contain information about different topics, including but not limited to history, science, technology, and more.\\n\\nMy training data is sourced from various places, including but not limited to:\\n\\n1. **Common Crawl**: A non-profit organization that crawls the web and makes the data available for research and development.\\n2. **Wikipedia**: A free online encyclopedia that provides a vast amount of knowledge on various topics.\\n3. **Books and academic papers**: I've been trained on a large collection of books and academic papers to learn about different subjects and domains.\\n4. **Online forums and discussions**: I've been trained on various online forums and discussions to learn about different topics, opinions, and perspectives.\\n5. **Product reviews and ratings**: I've been trained on a large amount of product reviews and ratings to learn about different products and services.\\n\\nMy training data is constantly updated and expanded to keep my knowledge up-to-date and to improve my performance.\\n\\nI'm a large language model, I don't have personal experiences, emotions, or opinions. My responses are generated based on patterns and relationships in the data I've been trained on.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 426, 'prompt_tokens': 16, 'total_tokens': 442, 'completion_time': 1.344802009, 'prompt_time': 0.000286179, 'queue_time': 0.012790188000000001, 'total_time': 1.345088188}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-b48f3626-44a8-4933-a8bd-8de018749410-0' usage_metadata={'input_tokens': 16, 'output_tokens': 426, 'total_tokens': 442}\n",
            "Assistant: I am trained on a massive dataset of text from various sources, including but not limited to:\n",
            "\n",
            "1. **Web pages**: I was trained on a large corpus of web pages to learn about various topics, styles, and formats.\n",
            "2. **Books and articles**: I have been trained on a vast collection of books and articles from different genres, domains, and languages.\n",
            "3. **User-generated content**: I've been trained on a large amount of user-generated content from social media, forums, and other online platforms.\n",
            "4. **Product reviews**: I've seen millions of product reviews to learn about different products, services, and opinions.\n",
            "5. **Conversations**: I've been trained on a vast amount of conversational data to learn how to respond to questions, statements, and prompts.\n",
            "6. **Knowledge graphs**: I have access to large knowledge graphs that contain structured data about entities, relationships, and concepts.\n",
            "7. **Databases**: I've been trained on various databases that contain information about different topics, including but not limited to history, science, technology, and more.\n",
            "\n",
            "My training data is sourced from various places, including but not limited to:\n",
            "\n",
            "1. **Common Crawl**: A non-profit organization that crawls the web and makes the data available for research and development.\n",
            "2. **Wikipedia**: A free online encyclopedia that provides a vast amount of knowledge on various topics.\n",
            "3. **Books and academic papers**: I've been trained on a large collection of books and academic papers to learn about different subjects and domains.\n",
            "4. **Online forums and discussions**: I've been trained on various online forums and discussions to learn about different topics, opinions, and perspectives.\n",
            "5. **Product reviews and ratings**: I've been trained on a large amount of product reviews and ratings to learn about different products and services.\n",
            "\n",
            "My training data is constantly updated and expanded to keep my knowledge up-to-date and to improve my performance.\n",
            "\n",
            "I'm a large language model, I don't have personal experiences, emotions, or opinions. My responses are generated based on patterns and relationships in the data I've been trained on.\n",
            "User: Can i trust you with the answers or results that you provide\n",
            "dict_values([{'messages': AIMessage(content=\"I'm designed to provide accurate and reliable information to the best of my abilities. Here are some reasons why you can trust me:\\n\\n1. **Knowledge base**: I have been trained on a massive dataset of text from various sources, including books, articles, and research papers. This training enables me to provide accurate and up-to-date information on a wide range of topics.\\n2. **Algorithmic checks**: My responses are generated using complex algorithms that are designed to ensure accuracy and consistency. These algorithms are regularly updated and refined to improve the quality of my responses.\\n3. **Continuous learning**: I learn from user interactions, which means I can adapt to new information and correct any mistakes I may make. This continuous learning process helps me improve my accuracy over time.\\n4. **Neutrality**: I'm designed to provide unbiased and neutral responses. I don't have personal opinions or agendas, and I strive to present information in a fair and balanced manner.\\n5. **Transparency**: If I'm unsure or don't know the answer to a question, I'll let you know. I'll also provide sources or references to support my responses when possible.\\n\\nHowever, it's important to note that I'm not perfect, and there are some limitations to my abilities:\\n\\n1. **Contextual understanding**: While I'm good at understanding natural language, I may not always understand the context or nuances of a question.\\n2. **Knowledge gaps**: My training data may not cover every topic or aspect of human knowledge, so I may not always have the answer to a question.\\n3. **Ambiguity**: If a question is ambiguous or open-ended, I may not always be able to provide a clear or accurate response.\\n\\nTo get the most accurate results from me, it's essential to:\\n\\n1. **Ask clear and specific questions**: Try to ask questions that are concise and well-defined.\\n2. **Provide context**: Give me as much context as possible about the topic or question you're asking about.\\n3. **Verify information**: If you're unsure about the accuracy of my response, verify the information through other trusted sources.\\n\\nBy working together and following these guidelines, I'm confident that I can provide you with accurate and helpful information.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 449, 'prompt_tokens': 22, 'total_tokens': 471, 'completion_time': 1.381745292, 'prompt_time': 0.000902847, 'queue_time': 0.043402878, 'total_time': 1.382648139}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run-e94b9d4b-1aa9-4d7a-b042-d48439966c10-0', usage_metadata={'input_tokens': 22, 'output_tokens': 449, 'total_tokens': 471})}])\n",
            "content=\"I'm designed to provide accurate and reliable information to the best of my abilities. Here are some reasons why you can trust me:\\n\\n1. **Knowledge base**: I have been trained on a massive dataset of text from various sources, including books, articles, and research papers. This training enables me to provide accurate and up-to-date information on a wide range of topics.\\n2. **Algorithmic checks**: My responses are generated using complex algorithms that are designed to ensure accuracy and consistency. These algorithms are regularly updated and refined to improve the quality of my responses.\\n3. **Continuous learning**: I learn from user interactions, which means I can adapt to new information and correct any mistakes I may make. This continuous learning process helps me improve my accuracy over time.\\n4. **Neutrality**: I'm designed to provide unbiased and neutral responses. I don't have personal opinions or agendas, and I strive to present information in a fair and balanced manner.\\n5. **Transparency**: If I'm unsure or don't know the answer to a question, I'll let you know. I'll also provide sources or references to support my responses when possible.\\n\\nHowever, it's important to note that I'm not perfect, and there are some limitations to my abilities:\\n\\n1. **Contextual understanding**: While I'm good at understanding natural language, I may not always understand the context or nuances of a question.\\n2. **Knowledge gaps**: My training data may not cover every topic or aspect of human knowledge, so I may not always have the answer to a question.\\n3. **Ambiguity**: If a question is ambiguous or open-ended, I may not always be able to provide a clear or accurate response.\\n\\nTo get the most accurate results from me, it's essential to:\\n\\n1. **Ask clear and specific questions**: Try to ask questions that are concise and well-defined.\\n2. **Provide context**: Give me as much context as possible about the topic or question you're asking about.\\n3. **Verify information**: If you're unsure about the accuracy of my response, verify the information through other trusted sources.\\n\\nBy working together and following these guidelines, I'm confident that I can provide you with accurate and helpful information.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 449, 'prompt_tokens': 22, 'total_tokens': 471, 'completion_time': 1.381745292, 'prompt_time': 0.000902847, 'queue_time': 0.043402878, 'total_time': 1.382648139}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-e94b9d4b-1aa9-4d7a-b042-d48439966c10-0' usage_metadata={'input_tokens': 22, 'output_tokens': 449, 'total_tokens': 471}\n",
            "Assistant: I'm designed to provide accurate and reliable information to the best of my abilities. Here are some reasons why you can trust me:\n",
            "\n",
            "1. **Knowledge base**: I have been trained on a massive dataset of text from various sources, including books, articles, and research papers. This training enables me to provide accurate and up-to-date information on a wide range of topics.\n",
            "2. **Algorithmic checks**: My responses are generated using complex algorithms that are designed to ensure accuracy and consistency. These algorithms are regularly updated and refined to improve the quality of my responses.\n",
            "3. **Continuous learning**: I learn from user interactions, which means I can adapt to new information and correct any mistakes I may make. This continuous learning process helps me improve my accuracy over time.\n",
            "4. **Neutrality**: I'm designed to provide unbiased and neutral responses. I don't have personal opinions or agendas, and I strive to present information in a fair and balanced manner.\n",
            "5. **Transparency**: If I'm unsure or don't know the answer to a question, I'll let you know. I'll also provide sources or references to support my responses when possible.\n",
            "\n",
            "However, it's important to note that I'm not perfect, and there are some limitations to my abilities:\n",
            "\n",
            "1. **Contextual understanding**: While I'm good at understanding natural language, I may not always understand the context or nuances of a question.\n",
            "2. **Knowledge gaps**: My training data may not cover every topic or aspect of human knowledge, so I may not always have the answer to a question.\n",
            "3. **Ambiguity**: If a question is ambiguous or open-ended, I may not always be able to provide a clear or accurate response.\n",
            "\n",
            "To get the most accurate results from me, it's essential to:\n",
            "\n",
            "1. **Ask clear and specific questions**: Try to ask questions that are concise and well-defined.\n",
            "2. **Provide context**: Give me as much context as possible about the topic or question you're asking about.\n",
            "3. **Verify information**: If you're unsure about the accuracy of my response, verify the information through other trusted sources.\n",
            "\n",
            "By working together and following these guidelines, I'm confident that I can provide you with accurate and helpful information.\n",
            "User: q\n",
            "Good Bye\n"
          ]
        }
      ]
    }
  ]
}